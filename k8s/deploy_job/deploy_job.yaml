apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: sparkjob
  namespace: default
spec:
  type: Python
  mode: cluster
  image: asoushawk/pyspark-docker:dev
  imagePullPolicy: Always
  mainApplicationFile: "local:///app/sample_pyspark_job.py"
  sparkVersion: "3.0.0"
  driver:
    envVars:
      AWS_KEY: ""
      AWS_SECRET: ""
      FILE_PATH: ""
    cores: 1
    coreLimit: "1200m"
    memory: "512m"
    labels:
      version: 3.0.0
    serviceAccount: spark-spark


  executor:
    cores: 1
    instances: 2
    memory: "512m"
    labels:
      version: 3.0.0


